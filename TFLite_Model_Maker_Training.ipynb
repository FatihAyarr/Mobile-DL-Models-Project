{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "952d5a9f",
      "metadata": {
        "id": "952d5a9f"
      },
      "source": [
        "TFLite Model Maker Tensorflow Documentation: https://www.tensorflow.org/lite/models/modify/model_maker/image_classification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbdaae47",
      "metadata": {
        "id": "dbdaae47"
      },
      "source": [
        "### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abb2184e",
      "metadata": {
        "id": "abb2184e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import image_classifier\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker.config import QuantizationConfig\n",
        "from tflite_model_maker.image_classifier import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "962557d8",
      "metadata": {
        "id": "962557d8",
        "outputId": "dc1e1972-a1d6-4a63-e618-ca3279312bc4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__  #2.4.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1b5f0bb",
      "metadata": {
        "id": "d1b5f0bb",
        "outputId": "87c19a99-69a7-431c-cfa7-13c99cf88630"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.test.is_gpu_available() # gpu is avaliable or not"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16b65b0b",
      "metadata": {
        "id": "16b65b0b"
      },
      "source": [
        "### Train set path\n",
        "- The path of the folder containing the train set is entered here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbe27d49",
      "metadata": {
        "id": "dbe27d49"
      },
      "outputs": [],
      "source": [
        "image_path = os.path.join(os.path.dirname(\"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "988e9ea8",
      "metadata": {
        "id": "988e9ea8"
      },
      "source": [
        "### Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ebb97c3",
      "metadata": {
        "id": "0ebb97c3",
        "outputId": "b098aef5-3cee-4288-a59b-f3a62d19542c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Load image with size: 40671, num_label: 2, labels: fincan, red.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Load image with size: 40671, num_label: 2, labels: fincan, red.\n"
          ]
        }
      ],
      "source": [
        "data = DataLoader.from_folder(image_path)\n",
        "train_data, test_data = data.split(0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3f0845c",
      "metadata": {
        "id": "d3f0845c"
      },
      "source": [
        "### Train, test and export the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dff3f7ab",
      "metadata": {
        "id": "dff3f7ab"
      },
      "source": [
        "### Simple Version:\n",
        "#### Simple version to create, evaluate, and export the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93bd9497",
      "metadata": {
        "id": "93bd9497",
        "outputId": "c54479df-e1fb-4e5a-cd31-62887c4b1e5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Retraining the models...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "hub_keras_layer_v1v2 (HubKer (None, 1280)              3413024   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 2562      \n",
            "=================================================================\n",
            "Total params: 3,415,586\n",
            "Trainable params: 2,562\n",
            "Non-trainable params: 3,413,024\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1143/1143 [==============================] - 173s 104ms/step - loss: 0.2471 - accuracy: 0.9778\n",
            "Epoch 2/5\n",
            "1143/1143 [==============================] - 119s 104ms/step - loss: 0.2173 - accuracy: 0.9959\n",
            "Epoch 3/5\n",
            "1143/1143 [==============================] - 119s 104ms/step - loss: 0.2161 - accuracy: 0.9964\n",
            "Epoch 4/5\n",
            "1143/1143 [==============================] - 119s 104ms/step - loss: 0.2156 - accuracy: 0.9963\n",
            "Epoch 5/5\n",
            "1143/1143 [==============================] - 119s 104ms/step - loss: 0.2153 - accuracy: 0.9965\n",
            "128/128 [==============================] - 76s 478ms/step - loss: 0.2137 - accuracy: 0.9961\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpto8q09d4/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpto8q09d4/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving labels in /tmp/tmp7ev94kqj/labels.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving labels in /tmp/tmp7ev94kqj/labels.txt\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:TensorFlow Lite model exported successfully: ./model3_new.tflite\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:TensorFlow Lite model exported successfully: ./model3_new.tflite\n"
          ]
        }
      ],
      "source": [
        "# Create the model.\n",
        "model = image_classifier.create(train_data)\n",
        "\n",
        "# Evaluate the model.\n",
        "loss, accuracy = model.evaluate(test_data)\n",
        "\n",
        "# Export to Tensorflow Lite model and label file in `export_dir`.\n",
        "model.export(export_dir='./', tflite_filename='model.tflite')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7949f118",
      "metadata": {
        "id": "7949f118"
      },
      "source": [
        "### Advanced and Detailed Version:\n",
        "\n",
        "modelspec = Enter the link of the model (feature vector) to do transfer learning. The larger the selected feature vector, the larger the model exported by the model maker.\n",
        "Different feature vectors can be selected from https://tfhub.dev/s?module-type=image-feature-vector&tf-version=tf2.\n",
        "\n",
        "\n",
        "Enter the input values of the selected feature vector in modelspec.input_image_shape = [224,224].\n",
        "\n",
        "There are 2 different quantization methods; dynamic and float16. Both of them give different results in model reduction rates and performance values. If the model is not to be quantized, the quantization_config=config part should be removed.\n",
        "*italicized text*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fb9611d",
      "metadata": {
        "id": "9fb9611d",
        "outputId": "8039a5ff-b757-452f-bd72-ab1674ac0ab3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Retraining the models...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Retraining the models...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "hub_keras_layer_v1v2_2 (HubK (None, 1024)              1026552   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 2050      \n",
            "=================================================================\n",
            "Total params: 1,028,602\n",
            "Trainable params: 1,018,922\n",
            "Non-trainable params: 9,680\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "1143/1143 [==============================] - 131s 110ms/step - loss: 0.4861 - accuracy: 0.9787\n",
            "Epoch 2/5\n",
            "1143/1143 [==============================] - 126s 110ms/step - loss: 0.4464 - accuracy: 0.9984\n",
            "Epoch 3/5\n",
            "1143/1143 [==============================] - 126s 110ms/step - loss: 0.4401 - accuracy: 0.9998\n",
            "Epoch 4/5\n",
            "1143/1143 [==============================] - 126s 110ms/step - loss: 0.4362 - accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "1143/1143 [==============================] - 126s 111ms/step - loss: 0.4329 - accuracy: 1.0000\n",
            "128/128 [==============================] - 29s 102ms/step - loss: 0.4361 - accuracy: 0.9968\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpci9abz84/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpci9abz84/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving labels in /tmp/tmp25qo_q3g/labels.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving labels in /tmp/tmp25qo_q3g/labels.txt\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:TensorFlow Lite model exported successfully: ./model840_new.tflite\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:TensorFlow Lite model exported successfully: ./model840_new.tflite\n"
          ]
        }
      ],
      "source": [
        "modelspec = image_classifier.ModelSpec(\n",
        "    uri='https://tfhub.dev/google/imagenet/mobilenet_v3_small_075_224/feature_vector/5')\n",
        "\n",
        "modelspec.input_image_shape = [224,224] #modelspec.input_image_shape = [xxx,xxx] In the xxx field enter the size written in the documentation of the selected vector.\n",
        "\n",
        "model = image_classifier.create(train_data, model_spec=modelspec, epochs=5, learning_rate=0.013,\n",
        "                                train_whole_model=True, shuffle=False, use_augmentation=False)\n",
        "\n",
        "# Evaluate the model.\n",
        "loss, accuracy = model.evaluate(test_data)\n",
        "\n",
        "# Export to Tensorflow Lite model and label file in `export_dir`.\n",
        "config = QuantizationConfig.for_dynamic()\n",
        "#config = QuantizationConfig.for_float16()\n",
        "\n",
        "model.export(export_dir='./', tflite_filename='model.tflite', quantization_config=config)\n",
        "#model.export(export_dir='./', tflite_filename='model.tflite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ffc64ff",
      "metadata": {
        "id": "4ffc64ff"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "tf"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}