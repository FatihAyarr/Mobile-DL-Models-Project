{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "952d5a9f",
   "metadata": {},
   "source": [
    "TFLite Model Maker Tensorflow Documentation: https://www.tensorflow.org/lite/models/modify/model_maker/image_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdaae47",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abb2184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import image_classifier\n",
    "from tflite_model_maker.config import ExportFormat\n",
    "from tflite_model_maker.config import QuantizationConfig\n",
    "from tflite_model_maker.image_classifier import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "962557d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__  #2.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1b5f0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available() # gpu is avaliable or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b65b0b",
   "metadata": {},
   "source": [
    "### Train set path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbe27d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = os.path.join(os.path.dirname(\"/home/ubuntu/FatihNewModel/Datasets/TFLite_56-44/train\"))\n",
    "#/home/ubuntu/FatihNewModel/Datasets/TFLite_56-44/train = serverdaki train set \n",
    "#localde calisiliyorsa train set'in bulundugu path girilmeli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988e9ea8",
   "metadata": {},
   "source": [
    "### Train-Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ebb97c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Load image with size: 40671, num_label: 2, labels: fincan, red.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Load image with size: 40671, num_label: 2, labels: fincan, red.\n"
     ]
    }
   ],
   "source": [
    "data = DataLoader.from_folder(image_path)\n",
    "train_data, test_data = data.split(0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f0845c",
   "metadata": {},
   "source": [
    "### Train, test and export the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff3f7ab",
   "metadata": {},
   "source": [
    "#### Simple version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93bd9497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Retraining the models...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hub_keras_layer_v1v2 (HubKer (None, 1280)              3413024   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 2562      \n",
      "=================================================================\n",
      "Total params: 3,415,586\n",
      "Trainable params: 2,562\n",
      "Non-trainable params: 3,413,024\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "1143/1143 [==============================] - 173s 104ms/step - loss: 0.2471 - accuracy: 0.9778\n",
      "Epoch 2/5\n",
      "1143/1143 [==============================] - 119s 104ms/step - loss: 0.2173 - accuracy: 0.9959\n",
      "Epoch 3/5\n",
      "1143/1143 [==============================] - 119s 104ms/step - loss: 0.2161 - accuracy: 0.9964\n",
      "Epoch 4/5\n",
      "1143/1143 [==============================] - 119s 104ms/step - loss: 0.2156 - accuracy: 0.9963\n",
      "Epoch 5/5\n",
      "1143/1143 [==============================] - 119s 104ms/step - loss: 0.2153 - accuracy: 0.9965\n",
      "128/128 [==============================] - 76s 478ms/step - loss: 0.2137 - accuracy: 0.9961\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpto8q09d4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpto8q09d4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving labels in /tmp/tmp7ev94kqj/labels.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving labels in /tmp/tmp7ev94kqj/labels.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:TensorFlow Lite model exported successfully: ./model3_new.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:TensorFlow Lite model exported successfully: ./model3_new.tflite\n"
     ]
    }
   ],
   "source": [
    "# Create the model.\n",
    "model = image_classifier.create(train_data)\n",
    "\n",
    "# Evaluate the model.\n",
    "loss, accuracy = model.evaluate(test_data)\n",
    "\n",
    "# Export to Tensorflow Lite model and label file in `export_dir`.\n",
    "model.export(export_dir='./', tflite_filename='model.tflite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7949f118",
   "metadata": {},
   "source": [
    "#### Advanced and detailed version:\n",
    "\n",
    "modelspec = transfer learning yapilacak modelin(feature vector) linki girilir. secilen feature vector ne kadar buyukse model maker'in export ettigi model de o kadar buyuk olur. \n",
    "https://tfhub.dev/s?module-type=image-feature-vector&tf-version=tf2 linkinden farkli feature vectorler secilebilir.\n",
    "\n",
    "\n",
    "modelspec.input_image_shape = [224,224] koduna secilen feature vector'un input degerleri girilir.\n",
    "\n",
    "2 farkli quantization yontemi var. dynamic ve float16. ikisinin modeli kucultme oranlari ve performans degerleri farkli sonuclar veriyor. model quantize edilmek istenmiyorsa ,quantization_config=config kismi cikartilmalidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fb9611d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hub_keras_layer_v1v2_2 (HubK (None, 1024)              1026552   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 1,028,602\n",
      "Trainable params: 1,018,922\n",
      "Non-trainable params: 9,680\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "1143/1143 [==============================] - 131s 110ms/step - loss: 0.4861 - accuracy: 0.9787\n",
      "Epoch 2/5\n",
      "1143/1143 [==============================] - 126s 110ms/step - loss: 0.4464 - accuracy: 0.9984\n",
      "Epoch 3/5\n",
      "1143/1143 [==============================] - 126s 110ms/step - loss: 0.4401 - accuracy: 0.9998\n",
      "Epoch 4/5\n",
      "1143/1143 [==============================] - 126s 110ms/step - loss: 0.4362 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "1143/1143 [==============================] - 126s 111ms/step - loss: 0.4329 - accuracy: 1.0000\n",
      "128/128 [==============================] - 29s 102ms/step - loss: 0.4361 - accuracy: 0.9968\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpci9abz84/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpci9abz84/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Label file is inside the TFLite model with metadata.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving labels in /tmp/tmp25qo_q3g/labels.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving labels in /tmp/tmp25qo_q3g/labels.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:TensorFlow Lite model exported successfully: ./model840_new.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:TensorFlow Lite model exported successfully: ./model840_new.tflite\n"
     ]
    }
   ],
   "source": [
    "modelspec = image_classifier.ModelSpec(\n",
    "    uri='https://tfhub.dev/google/imagenet/mobilenet_v3_small_075_224/feature_vector/5')\n",
    "##modelspec.input_image_shape = [xxx,xxx] xxx field'ina secilen vektorun dokumantasyonunda yazan boyut girilir.\n",
    "modelspec.input_image_shape = [224,224]\n",
    "\n",
    "model = image_classifier.create(train_data, model_spec=modelspec, epochs=5, learning_rate=0.013,\n",
    "                                train_whole_model=True, shuffle=False, use_augmentation=False)\n",
    "\n",
    "# Evaluate the model.\n",
    "loss, accuracy = model.evaluate(test_data)\n",
    "\n",
    "# Export to Tensorflow Lite model and label file in `export_dir`.\n",
    "config = QuantizationConfig.for_dynamic()\n",
    "#config = QuantizationConfig.for_float16()\n",
    "model.export(export_dir='./', tflite_filename='model.tflite', quantization_config=config)\n",
    "#model.export(export_dir='./', tflite_filename='model.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffc64ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
